# manage_docs.py
"""
docs_ald.json ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸

- stats : í‚¤ì›Œë“œë³„ ë¬¸ì¥ ê°œìˆ˜ í†µê³„ ì¶œë ¥
- group : í‚¤ì›Œë“œë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ë¬¸ì„œ ë³´ê¸°
- add   : í‚¤ì›Œë“œ + ë¬¸ì¥ ì¶”ê°€ (ì¸í„°ë™í‹°ë¸Œ OR ì˜µì…˜ ì…ë ¥)

ì‚¬ìš© ì˜ˆì‹œ:
    cd ~/ald-rag-lab
    python manage_docs.py stats
    python manage_docs.py group
    python manage_docs.py add
    python manage_docs.py add --keyword Precursor --text "ìƒˆë¡œ ì¶”ê°€í•  ë¬¸ì¥..."
"""

import argparse
import json
from pathlib import Path
from typing import Any, Dict, List

BASE_DIR = Path(__file__).resolve().parent.parent.parent  # ~/ald-rag-lab
DOCS_PATH = BASE_DIR / "docs" / "docs_ald.json"


# ==============================
# 1) íŒŒì¼ ìœ í‹¸
# ==============================

def load_raw_docs() -> Dict[str, List[Dict[str, str]]]:
    """
    docs_ald.jsonì„ ì½ì–´ì„œ í‚¤ì›Œë“œë³„ ê·¸ë£¹í™”ëœ êµ¬ì¡°ë¥¼ ë°˜í™˜.
    - ìƒˆ í¬ë§·: { "documents": {"ALD": [{"text": "..."}, ...], ...} }
    - ê¸°ì¡´ í¬ë§· í˜¸í™˜: { "documents": [{"keyword": "ALD", "text": "..."}, ...] }
    """
    if not DOCS_PATH.exists():
        print(f"[WARN] {DOCS_PATH} ê°€ ì•„ì§ ì—†ìŒ. ìƒˆë¡œ ìƒì„±í•  ì˜ˆì •.")
        return {}

    with DOCS_PATH.open("r", encoding="utf-8") as f:
        data = json.load(f)

    if isinstance(data, dict) and "documents" in data:
        documents = data["documents"]
        
        # ìƒˆ êµ¬ì¡° (í‚¤ì›Œë“œë³„ ê·¸ë£¹í™”)
        if isinstance(documents, dict):
            return documents
        
        # ê¸°ì¡´ êµ¬ì¡° (ë¦¬ìŠ¤íŠ¸) - ìƒˆ êµ¬ì¡°ë¡œ ë³€í™˜
        elif isinstance(documents, list):
            grouped: Dict[str, List[Dict[str, str]]] = {}
            for item in documents:
                if not isinstance(item, dict):
                    continue
                keyword = str(item.get("keyword", "unknown")).strip() or "unknown"
                text = str(item.get("text", "")).strip()
                if not text:
                    continue
                if keyword not in grouped:
                    grouped[keyword] = []
                grouped[keyword].append({"text": text})
            return grouped

    print("[WARN] docs_ald.json êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„. ë¹ˆ dict ë°˜í™˜.")
    return {}


def save_raw_docs(docs: Dict[str, List[Dict[str, str]]]) -> None:
    """
    í‚¤ì›Œë“œë³„ ê·¸ë£¹í™”ëœ êµ¬ì¡°ë¡œ ì €ì¥:
    {
      "documents": {
        "ALD": [{"text": "..."}, ...],
        "Precursor": [{"text": "..."}, ...],
        ...
      }
    }
    """
    DOCS_PATH.parent.mkdir(exist_ok=True, parents=True)
    wrapper = {"documents": docs}
    total_count = sum(len(texts) for texts in docs.values())
    with DOCS_PATH.open("w", encoding="utf-8") as f:
        json.dump(wrapper, f, ensure_ascii=False, indent=2)
    print(f"[INFO] ì €ì¥ ì™„ë£Œ: {DOCS_PATH} (ì´ {total_count} ë¬¸ì¥, {len(docs)} í‚¤ì›Œë“œ)")


def get_next_id(docs: Dict[str, List[Dict[str, str]]]) -> int:
    """IDëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€"""
    return 1


# ==============================
# 2) stats ëª¨ë“œ
# ==============================

def run_stats():
    if not DOCS_PATH.exists():
        print(f"[stats] {DOCS_PATH} ê°€ ì—†ìŒ.")
        return

    docs = load_raw_docs()
    if not docs:
        print("[stats] ë¬¸ì„œê°€ ë¹„ì–´ ìˆìŒ.")
        return

    print("\n[í‚¤ì›Œë“œ í†µê³„] (docs_ald.json ê¸°ì¤€)")
    for kw in sorted(docs.keys()):
        count = len(docs[kw])
        print(f"- {kw}: {count} ë¬¸ì¥")


# ==============================
# 2-1) group ëª¨ë“œ: í‚¤ì›Œë“œë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ë³´ê¸°
# ==============================

def run_group():
    """
    í‚¤ì›Œë“œë³„ë¡œ ë¬¸ì„œë¥¼ ê·¸ë£¹í™”í•´ì„œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    """
    if not DOCS_PATH.exists():
        print(f"[group] {DOCS_PATH} ê°€ ì—†ìŒ.")
        return

    docs = load_raw_docs()
    if not docs:
        print("[group] ë¬¸ì„œê°€ ë¹„ì–´ ìˆìŒ.")
        return

    print("\n" + "=" * 80)
    print("[í‚¤ì›Œë“œë³„ ë¬¸ì„œ ê·¸ë£¹]")
    print("=" * 80)

    total_count = 0
    for kw in sorted(docs.keys()):
        items = docs[kw]
        total_count += len(items)
        print(f"\nğŸ“Œ keyword = {kw} ({len(items)}ê°œ)")
        print("-" * 80)
        for idx, item in enumerate(items, 1):
            if isinstance(item, dict):
                text = item.get("text", "").strip()
            else:
                text = str(item).strip()
            print(f"  {idx}. {text}")
    
    print("\n" + "=" * 80)
    print(f"ì´ {total_count}ê°œ ë¬¸ì„œ, {len(docs)}ê°œ í‚¤ì›Œë“œ")
    print("=" * 80)


# ==============================
# 3) add ëª¨ë“œ
# ==============================

def run_add(keyword: str, text: str):
    docs = load_raw_docs()

    # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
    if not keyword:
        keyword = input("í‚¤ì›Œë“œ ì…ë ¥ (ì˜ˆ: Precursor, Purge, Plasma, MFC, Flow...): ").strip()
    if not text:
        text = input("ë¬¸ì¥ ì…ë ¥: ").strip()

    if not keyword or not text:
        print("[ERROR] í‚¤ì›Œë“œì™€ ë¬¸ì¥ì€ ë¹„ì–´ìˆìœ¼ë©´ ì•ˆ ë¨.")
        return

    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if keyword not in docs:
        docs[keyword] = []

    # ìƒˆ í•­ëª© ì¶”ê°€
    docs[keyword].append({"text": text})
    save_raw_docs(docs)

    print("\n[ì¶”ê°€ëœ í•­ëª©]")
    print(f"- keyword : {keyword}")
    print(f"- text    : {text}")
    print(f"- ì´ {len(docs[keyword])}ê°œ í•­ëª© (í‚¤ì›Œë“œ '{keyword}' ê¸°ì¤€)")


# ==============================
# 4) ë©”ì¸
# ==============================

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="docs_ald.json ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸")
    sub = parser.add_subparsers(dest="command", required=True)

    # stats
    sub.add_parser("stats", help="í‚¤ì›Œë“œë³„ ë¬¸ì¥ ê°œìˆ˜ í†µê³„ ì¶œë ¥")

    # group
    sub.add_parser("group", help="í‚¤ì›Œë“œë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ë¬¸ì„œ ë³´ê¸°")

    # add
    p_add = sub.add_parser("add", help="ë¬¸ì¥ ì¶”ê°€")
    p_add.add_argument("--keyword", type=str, default="", help="í‚¤ì›Œë“œ (ì—†ìœ¼ë©´ ì¸í„°ë™í‹°ë¸Œ)")
    p_add.add_argument("--text", type=str, default="", help="ë¬¸ì¥ ë‚´ìš© (ì—†ìœ¼ë©´ ì¸í„°ë™í‹°ë¸Œ)")

    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    if args.command == "stats":
        run_stats()
    elif args.command == "group":
        run_group()
    elif args.command == "add":
        run_add(args.keyword, args.text)
