#!/usr/bin/env python3
"""
ì‹¤ì œ ë¬¸ì„œ(ë§¤ë‰´ì–¼, PDF, í…ìŠ¤íŠ¸ íŒŒì¼)ì—ì„œ ì „ë¬¸ì ì¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë„êµ¬

ì‚¬ìš© ì˜ˆì‹œ:
    # í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¶”ì¶œ
    python extract_from_docs.py text --file manual.txt --keyword ALD

    # PDFì—ì„œ ì¶”ì¶œ (PyPDF2 í•„ìš”)
    python extract_from_docs.py pdf --file manual.pdf --keyword MFC

    # ì—¬ëŸ¬ í‚¤ì›Œë“œ í•œë²ˆì—
    python extract_from_docs.py text --file manual.txt --keywords ALD,Precursor,Purge
"""

import argparse
import re
import sys
from pathlib import Path
from typing import List, Dict, Set

BASE_DIR = Path(__file__).resolve().parent.parent  # ~/ald-rag-lab
DOCS_PATH = BASE_DIR / "docs" / "docs_ald.json"

# PDF ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„ íƒì  import
try:
    import PyPDF2  # type: ignore
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False


def load_docs() -> Dict[str, List[Dict[str, str]]]:
    """docs_ald.json ë¡œë“œ"""
    if not DOCS_PATH.exists():
        return {}
    
    import json
    with DOCS_PATH.open("r", encoding="utf-8") as f:
        data = json.load(f)
    
    return data.get("documents", {})


def save_docs(docs: Dict[str, List[Dict[str, str]]]) -> None:
    """docs_ald.json ì €ì¥"""
    import json
    DOCS_PATH.parent.mkdir(exist_ok=True, parents=True)
    data = {"documents": docs}
    with DOCS_PATH.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    total = sum(len(texts) for texts in docs.values())
    print(f"[+] ì €ì¥ ì™„ë£Œ: {len(docs)}ê°œ í‚¤ì›Œë“œ, {total}ê°œ ë¬¸ì„œ")


def extract_from_text(text: str, keywords: List[str]) -> Dict[str, List[str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ"""
    results: Dict[str, List[str]] = {kw: [] for kw in keywords}
    
    # ë¬¸ì¥ ë¶„ë¦¬ (ê°„ë‹¨í•œ ë°©ë²•)
    sentences = re.split(r'[.!?]\s+', text)
    
    for sentence in sentences:
        sentence = sentence.strip()
        if len(sentence) < 20:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸
            continue
        
        # ê° í‚¤ì›Œë“œì— ëŒ€í•´ ë§¤ì¹­ í™•ì¸
        for keyword in keywords:
            # í‚¤ì›Œë“œê°€ ë¬¸ì¥ì— í¬í•¨ë˜ì–´ ìˆê³ , êµ¬ì²´ì ì¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if keyword.lower() in sentence.lower():
                # êµ¬ì²´ì ì¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸ (ìˆ˜ì¹˜, ë²”ìœ„ ë“±)
                has_specific_info = (
                    re.search(r'\d+', sentence) or  # ìˆ«ì í¬í•¨
                    re.search(r'[â„ƒÂ°C]|sccm|Torr|W|Hz|%', sentence) or  # ë‹¨ìœ„ í¬í•¨
                    len(sentence) > 30  # ì¶©ë¶„í•œ ê¸¸ì´
                )
                
                if has_specific_info:
                    # ì¼ë°˜ì ì¸ í‘œí˜„ ì œê±°
                    if not any(word in sentence for word in ['ì¤‘ìš”í•˜ë‹¤', 'í•„ìš”í•˜ë‹¤', 'ì¢‹ë‹¤', 'ë‚˜ì˜ë‹¤', 'ì¼ë°˜ì ìœ¼ë¡œ', 'ë³´í†µ']):
                        if sentence not in results[keyword]:
                            results[keyword].append(sentence)
    
    return results


def extract_from_pdf(pdf_path: Path, keywords: List[str]) -> Dict[str, List[str]]:
    """PDFì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ"""
    if not PDF_AVAILABLE:
        raise RuntimeError("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install PyPDF2' ì‹¤í–‰í•˜ì„¸ìš”.")
    
    results: Dict[str, List[str]] = {kw: [] for kw in keywords}
    
    with pdf_path.open('rb') as f:
        pdf_reader = PyPDF2.PdfReader(f)
        
        for page_num, page in enumerate(pdf_reader.pages):
            text = page.extract_text()
            page_results = extract_from_text(text, keywords)
            
            for keyword in keywords:
                results[keyword].extend(page_results[keyword])
    
    return results


def filter_quality_sentences(sentences: List[str]) -> List[str]:
    """ë¬¸ì¥ í’ˆì§ˆ í•„í„°ë§"""
    filtered = []
    
    for sentence in sentences:
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ë©´ ì œì™¸
        if len(sentence) < 20 or len(sentence) > 200:
            continue
        
        # ì¼ë°˜ì ì¸ í‘œí˜„ ì œì™¸
        general_words = ['ì¤‘ìš”í•˜ë‹¤', 'í•„ìš”í•˜ë‹¤', 'ì¢‹ë‹¤', 'ë‚˜ì˜ë‹¤', 'ì¼ë°˜ì ìœ¼ë¡œ', 'ë³´í†µ', 'ëŒ€ë¶€ë¶„']
        if any(word in sentence for word in general_words):
            continue
        
        # êµ¬ì²´ì ì¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_specific = (
            re.search(r'\d+', sentence) or
            re.search(r'[â„ƒÂ°C]|sccm|Torr|W|Hz|%|bar|Pa', sentence)
        )
        
        if has_specific:
            filtered.append(sentence)
    
    return filtered


def run_text_mode(file_path: str, keywords: List[str], auto_add: bool = False):
    """í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¶”ì¶œ"""
    path = Path(file_path)
    if not path.exists():
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return
    
    print(f"[+] í…ìŠ¤íŠ¸ íŒŒì¼ ì½ëŠ” ì¤‘: {file_path}")
    with path.open("r", encoding="utf-8") as f:
        text = f.read()
    
    print(f"[+] í‚¤ì›Œë“œ ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ ì¤‘: {', '.join(keywords)}")
    results = extract_from_text(text, keywords)
    
    # í’ˆì§ˆ í•„í„°ë§
    for keyword in keywords:
        results[keyword] = filter_quality_sentences(results[keyword])
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("[ì¶”ì¶œëœ ë¬¸ì¥ë“¤]")
    print("=" * 80)
    
    docs = load_docs()
    new_count = 0
    
    for keyword in keywords:
        sentences = results[keyword]
        if not sentences:
            print(f"\nğŸ“Œ {keyword}: (ì¶”ì¶œëœ ë¬¸ì¥ ì—†ìŒ)")
            continue
        
        print(f"\nğŸ“Œ {keyword}: {len(sentences)}ê°œ ë¬¸ì¥")
        print("-" * 80)
        
        for i, sentence in enumerate(sentences[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            print(f"  {i}. {sentence}")
        
        if len(sentences) > 10:
            print(f"  ... ì™¸ {len(sentences) - 10}ê°œ")
        
        # ìë™ ì¶”ê°€ ë˜ëŠ” í™•ì¸
        if auto_add:
            if keyword not in docs:
                docs[keyword] = []
            
            for sentence in sentences:
                if {"text": sentence} not in docs[keyword]:
                    docs[keyword].append({"text": sentence})
                    new_count += 1
        else:
            confirm = input(f"\nìœ„ {len(sentences)}ê°œ ë¬¸ì¥ì„ '{keyword}' í‚¤ì›Œë“œì— ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if confirm == 'y':
                if keyword not in docs:
                    docs[keyword] = []
                
                for sentence in sentences:
                    if {"text": sentence} not in docs[keyword]:
                        docs[keyword].append({"text": sentence})
                        new_count += 1
    
    if new_count > 0:
        save_docs(docs)
        print(f"\n[âœ“] ì´ {new_count}ê°œ ë¬¸ì¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\n[!] ì¶”ê°€ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")


def run_pdf_mode(file_path: str, keywords: List[str], auto_add: bool = False):
    """PDF íŒŒì¼ì—ì„œ ì¶”ì¶œ"""
    path = Path(file_path)
    if not path.exists():
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return
    
    if not PDF_AVAILABLE:
        print("[ERROR] PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("        ì„¤ì¹˜: pip install PyPDF2")
        return
    
    print(f"[+] PDF íŒŒì¼ ì½ëŠ” ì¤‘: {file_path}")
    results = extract_from_pdf(path, keywords)
    
    # í’ˆì§ˆ í•„í„°ë§
    for keyword in keywords:
        results[keyword] = filter_quality_sentences(results[keyword])
    
    # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ (í…ìŠ¤íŠ¸ ëª¨ë“œì™€ ë™ì¼)
    print("\n" + "=" * 80)
    print("[ì¶”ì¶œëœ ë¬¸ì¥ë“¤]")
    print("=" * 80)
    
    docs = load_docs()
    new_count = 0
    
    for keyword in keywords:
        sentences = results[keyword]
        if not sentences:
            print(f"\nğŸ“Œ {keyword}: (ì¶”ì¶œëœ ë¬¸ì¥ ì—†ìŒ)")
            continue
        
        print(f"\nğŸ“Œ {keyword}: {len(sentences)}ê°œ ë¬¸ì¥")
        print("-" * 80)
        
        for i, sentence in enumerate(sentences[:10], 1):
            print(f"  {i}. {sentence}")
        
        if len(sentences) > 10:
            print(f"  ... ì™¸ {len(sentences) - 10}ê°œ")
        
        if auto_add:
            if keyword not in docs:
                docs[keyword] = []
            
            for sentence in sentences:
                if {"text": sentence} not in docs[keyword]:
                    docs[keyword].append({"text": sentence})
                    new_count += 1
        else:
            confirm = input(f"\nìœ„ {len(sentences)}ê°œ ë¬¸ì¥ì„ '{keyword}' í‚¤ì›Œë“œì— ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if confirm == 'y':
                if keyword not in docs:
                    docs[keyword] = []
                
                for sentence in sentences:
                    if {"text": sentence} not in docs[keyword]:
                        docs[keyword].append({"text": sentence})
                        new_count += 1
    
    if new_count > 0:
        save_docs(docs)
        print(f"\n[âœ“] ì´ {new_count}ê°œ ë¬¸ì¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")


def parse_args():
    parser = argparse.ArgumentParser(description="ë¬¸ì„œì—ì„œ ì „ë¬¸ì ì¸ ì •ë³´ ì¶”ì¶œ")
    sub = parser.add_subparsers(dest="mode", required=True)
    
    # í…ìŠ¤íŠ¸ ëª¨ë“œ
    p_text = sub.add_parser("text", help="í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¶”ì¶œ")
    p_text.add_argument("--file", type=str, required=True, help="í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ")
    p_text.add_argument("--keywords", type=str, required=True, help="í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    p_text.add_argument("--auto", action="store_true", help="ìë™ ì¶”ê°€ (í™•ì¸ ì—†ì´)")
    
    # PDF ëª¨ë“œ
    p_pdf = sub.add_parser("pdf", help="PDF íŒŒì¼ì—ì„œ ì¶”ì¶œ")
    p_pdf.add_argument("--file", type=str, required=True, help="PDF íŒŒì¼ ê²½ë¡œ")
    p_pdf.add_argument("--keywords", type=str, required=True, help="í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    p_pdf.add_argument("--auto", action="store_true", help="ìë™ ì¶”ê°€ (í™•ì¸ ì—†ì´)")
    
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    
    keywords = [kw.strip() for kw in args.keywords.split(",")]
    
    if args.mode == "text":
        run_text_mode(args.file, keywords, args.auto)
    elif args.mode == "pdf":
        run_pdf_mode(args.file, keywords, args.auto)

